{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <오늘 할 것: 웹 서비스>\n",
    "\n",
    "# 1. HTTP 기초잡기\n",
    "- 1-1. HTTP\n",
    "- 1-2. HTML\n",
    "- 하이퍼링크의 혁신성\n",
    "    - 1-2-1. 문법 몇가지\n",
    "- 1-3. CSS\n",
    "\n",
    "# 2. Flask로 웹서버 만들기\n",
    "- 2-1. 폴더 구조 준비하기\n",
    "- 2-2. 문법/규칙 몇가지\n",
    "### - 2-3. Yolo/Face Detection 연동하기\n",
    "\n",
    "# 3. AWS로 구동하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. HTTP 기초잡기\n",
    "\n",
    "## 1-1. HTTP\n",
    "\n",
    "> **H**yper **T**ext **T**ransfer **P**rtocol\n",
    "- 웹에서 정보를 주고 받을 수 있는 가장 기본적인 프로토콜\n",
    "- 접속을 유지하지 않는 stateless 프로토콜\n",
    "    - 대규모 저복을 지원하기 위함\n",
    "- 클라이언트와 서버 사이에 이루어지는 요청&응답 프로토콜\n",
    "\n",
    "## 1-2. HTML\n",
    "> **H**yper **T**ext **M**arkup **L**anguage\n",
    "- 많은 수의 문서를 하이퍼링크로 서로 연결시킬 수 있는 문서 구조\n",
    "- 참조를 통해 한 문서에서 다른 문서로 즉시 접근할 수 있는 텍스트\n",
    "\n",
    "### 하이퍼링크의 혁신성\n",
    "- 기존 문서: 순차적, 서열형 구조\n",
    "- 하이퍼링크: 링크에 따라 그 차례가 임의적이면서 나열형 구조\n",
    "    - 작가의 의도대로 사용자가 따라가는 것이 아닌, 하이퍼링크로 연결된 문서들을 클릭에 따라 자유롭게 이동할 수 있도록 해줌.\n",
    "    - 패러다임의 변화\n",
    "<img src=web.jpg>\n",
    "\n",
    "\n",
    "### 1-2-1. 문법 몇가지\n",
    "- opening tag 와 closing tag로 내용을 감싼다.\n",
    "    - `<head>     </head>`\n",
    "- `\"`, `'` 모두 쓰고, 사실은 생략 가능하다.\n",
    "- 주석: `<!--  -->`\n",
    "\n",
    "\n",
    "## 1-3. CSS\n",
    "> **C**ascading **S**tyle **S**heets; HTML이 data라면, CSS는 view\n",
    "\n",
    "\n",
    "## 1-4. 모바일 지원 HTML\n",
    "\n",
    "모바일 viewport 지원 (디바이스 크기에 맞추어 페이지를 리사이징해서 보여줌)\n",
    "\n",
    "`<head>`\n",
    "\n",
    "`   <meta charset=\"utf-8\">`\n",
    "\n",
    "`   <meta name=\"viewport\" content=\"width=device-width initial-scale=1.0\">`\n",
    "\n",
    "`</head>`\n",
    "\n",
    "\n",
    "모바일 카메라 지원\n",
    "\n",
    "`<input type=\"file\" name =\"file1\" accept=\"image/*\" capture=\"camera\"/>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Flask로 웹서버 만들기\n",
    "\n",
    "### - 참조할 파일\n",
    "    - flaskapp.py\n",
    "    - home.html\n",
    "    - image.html\n",
    "    - view.html\n",
    "\n",
    "## 2-1. 폴더 구조 준비하기\n",
    "- app\n",
    "    - static\n",
    "        - css\n",
    "        - img\n",
    "        - js\n",
    "    - templates\n",
    "    - routes\n",
    "    - README.md\n",
    "\n",
    "#### * 중요: 디렉토리명은 꼭 똑같이 써줘야한다!\n",
    "\n",
    "## 2-2. 문법/규칙 몇가지\n",
    "- 파이썬과 html을 가급적이면 섞어서 쓰는 것을 피한다.\n",
    "    - app을 정의하는 py 파일에는 파이썬을\n",
    "    - 템플릿을 만드는 html 파일에는 html을 쓴다.\n",
    "    \n",
    "- 파이썬과 html을 엮을 때는 일련의 문법을 따른다.\n",
    "    - `flask` 에서 제공하는 `render_template` 메소드를 활용하면\n",
    "        - 변수 처리 : `{{변수}}`\n",
    "        - 반복문 : `{%  for문  %}    {%  endfor  %}`\n",
    "        - 조건문 : `{%   if문  %}    {%  endif   %}`\n",
    "    - 을 html에 끼워넣어서 py 파일과 html 파일을 연동시킬 수 있다.\n",
    "    \n",
    "- 예제: for문으로 이미지 띄우기\n",
    "    - flaskapp.py\n",
    "    <img src=flaskapp.jpg>\n",
    "    - image.html\n",
    "    <img src=image.html.jpg>\n",
    "    - 브라우저 출력 값\n",
    "    <img src=browser.jpg>\n",
    "    - 브라우저 소스보기\n",
    "    <img src=source.jpg>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html에 썼던 for문이 아주아주 잘 처리가 되었다!\n",
    "\n",
    "\n",
    "### 추가적으로 한 것\n",
    "- 이미지 업로드/저장\n",
    "- 업로드 성공 메세지 띄우기\n",
    "- alert 창 띄우기/목록으로 자동으로 돌아오기 (JS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Yolo/Face Detection 연동하기\n",
    "\n",
    "먼저 함수를 정의해준다.\n",
    "\n",
    "pycharm에서 짜면 에러 핸들링이 어렵기 때문에 주피터에서 1차 작업을 한 뒤에 서버 쪽으로 옮긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-1. Yolo\n",
    "\n",
    "아래 내용을 별도의 `yolo.py` 파일로 생성해서 메인 flaskapp 파일에서는 `import yolo`로 접근한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os.path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Initialize the parameters\n",
    "confThreshold = 0.5  #Confidence threshold; 컨피던스가 이 값 미만이면 무시할 것임; 관행적으로 0.5를 쓴다.\n",
    "nmsThreshold = 0.4   #Non-maximum suppression threshold; 주변보다 크거나 작은 값만 살림; \n",
    "inpWidth = 416       #Width of network's input image\n",
    "inpHeight = 416      #Height of network's input image\n",
    "\n",
    "# Load names of classes\n",
    "classesFile = \"coco.names\"    #클래스명을 정리한 텍스트파일\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "# Give the configuration and weight files for the model and load the network using them.\n",
    "modelConfiguration = \"yolov3.cfg\"     #네트워크를 구성하는 레이어들의 파라미터를 정리한 텍스트파일\n",
    "modelWeights = \"yolov3.weights\"       #모델 학습 결과 도출된 weight값을 정리한 파일\n",
    "\n",
    "net = cv.dnn.readNetFromDarknet(modelConfiguration, modelWeights)    #`readNetFromDarknet`: 외부 config 정보와 weight 정보로 네트워크 구축\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)    #백엔드 지정\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the names of the output layers;\n",
    "#아웃풋 레이어명을 리턴하는 함수\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Draw the predicted bounding box;\n",
    "#바운딩 박스 그리고 클래스 레이블/확률값 쓰는 함수\n",
    "def drawPred(frame, classId, conf, left, top, right, bottom):\n",
    "    # Draw a bounding box.;\n",
    "    #박스 그리기\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    \n",
    "    label = '%.2f' % conf\n",
    "        \n",
    "    # Get the label for the class name and its confidence\n",
    "    #클래스 레이블/확률값 구하기\n",
    "    if classes:\n",
    "        assert(classId < len(classes))\n",
    "        label = '%s:%s' % (classes[classId], label)\n",
    "\n",
    "    #Display the label at the top of the bounding box;\n",
    "    #클래스 레이블/확률값 쓸 위치 지정\n",
    "    labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "    top = max(top, labelSize[1])\n",
    "    cv.rectangle(frame, (left, top - round(1.5*labelSize[1])), (left + round(1.5*labelSize[0]), top + baseLine), (255, 255, 255), cv.FILLED)\n",
    "    cv.putText(frame, label, (left, top), cv.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,0), 1)\n",
    "\n",
    "# Remove the bounding boxes with low confidence using non-maxima suppression;\n",
    "#\n",
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]   #행 == 높이\n",
    "    frameWidth = frame.shape[1]    #열 == 폭\n",
    "\n",
    "    # Scan through all the bounding boxes output from the network and keep only the\n",
    "    # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "    classIds = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:     #yolo layer 출력값을 1개씩 취함; 3번 돈다.\n",
    "        for detection in out:     #바운딩박스 1개씩 취함; 507, 2028, 8112번 돈다.\n",
    "            scores = detection[5:]    #80개 클래스에 대한 확률값\n",
    "            classId = np.argmax(scores)     #가장 높은 확률값의 인덱스\n",
    "            confidence = scores[classId]    #가장 높은 확률\n",
    "            if confidence > confThreshold:    #확률이 미리 설정해둔 파라미터보다 높을 경우에만 실행된다.; confidence만으로도 많이 걸러짐\n",
    "                center_x = int(detection[0] * frameWidth)   #detection 값이 0~1로 정규화되기 때문에 원래 값으로 되돌리기 위해서 폭/높이를 곱해준다.\n",
    "                center_y = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2] * frameWidth)\n",
    "                height = int(detection[3] * frameHeight)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "                classIds.append(classId)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([left, top, width, height])\n",
    "\n",
    "    # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "    # lower confidences.\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    \n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        drawPred(frame, classIds[i], confidences[i], left, top, left + width, top + height)\n",
    "\n",
    "\n",
    "def yolo3(img):\n",
    "    cap = cv.VideoCapture(img)\n",
    "    hasFrame, frame = cap.read()\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(getOutputsNames(net))\n",
    "    postprocess(frame, outs)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency())\n",
    "    cv.putText(frame, label, (0, 15), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-2. Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T22:56:47.219429Z",
     "start_time": "2020-02-12T22:56:25.818795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : Male, conf = 0.950\n",
      "Age Output : [[1.5615560e-05 3.3251735e-04 3.1123275e-01 5.0079143e-01 1.8564637e-01\n",
      "  1.6352300e-03 2.4504005e-04 1.0102564e-04]]\n",
      "Age : (15-20), conf = 0.501\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import time\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Load network\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "padding = 25\n",
    "\n",
    "frame = cv.imread(\"test.jpg\")\n",
    "frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "for bbox in bboxes:\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        blob = cv.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        print(\"Age Output : {}\".format(agePreds))\n",
    "        print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv.putText(frameFace, label, (bbox[0], bbox[1]-10), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv.LINE_AA)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:36:28.309626Z",
     "start_time": "2020-02-12T23:36:28.302644Z"
    }
   },
   "outputs": [],
   "source": [
    "def detectFace(img):\n",
    "    frame = cv.imread(img)\n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "    for bbox in bboxes:\n",
    "            face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "            blob = cv.dnn.blobFromImage(face, 1.0, (227, 227),(78.4263377603, 87.7689143744, 114.895847746), swapRB=False)\n",
    "            genderNet.setInput(blob)\n",
    "            genderPreds = genderNet.forward()\n",
    "            gender = genderList[genderPreds[0].argmax()]\n",
    "\n",
    "            ageNet.setInput(blob)\n",
    "            agePreds = ageNet.forward()\n",
    "            age = ageList[agePreds[0].argmax()]\n",
    "\n",
    "            label = \"{},{}\".format(gender, age)\n",
    "            cv.putText(frameFace, label, (bbox[0], bbox[1]-10), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv.LINE_AA)        \n",
    "    return frameFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:36:29.178247Z",
     "start_time": "2020-02-12T23:36:29.126665Z"
    }
   },
   "outputs": [],
   "source": [
    "processed = detectFace('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:49:19.965931Z",
     "start_time": "2020-02-12T23:49:19.959949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[164, 136, 119],\n",
       "        [166, 138, 121],\n",
       "        [169, 141, 124],\n",
       "        ...,\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195]],\n",
       "\n",
       "       [[178, 150, 133],\n",
       "        [180, 152, 135],\n",
       "        [184, 156, 139],\n",
       "        ...,\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195]],\n",
       "\n",
       "       [[196, 168, 151],\n",
       "        [198, 170, 153],\n",
       "        [201, 173, 156],\n",
       "        ...,\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195],\n",
       "        [226, 206, 195]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[241, 203, 179],\n",
       "        [241, 203, 179],\n",
       "        [242, 204, 180],\n",
       "        ...,\n",
       "        [195, 170, 174],\n",
       "        [195, 170, 174],\n",
       "        [195, 170, 174]],\n",
       "\n",
       "       [[241, 203, 179],\n",
       "        [241, 203, 179],\n",
       "        [242, 204, 180],\n",
       "        ...,\n",
       "        [195, 170, 174],\n",
       "        [195, 170, 174],\n",
       "        [195, 170, 174]],\n",
       "\n",
       "       [[241, 203, 179],\n",
       "        [241, 203, 179],\n",
       "        [242, 204, 180],\n",
       "        ...,\n",
       "        [194, 169, 173],\n",
       "        [194, 169, 173],\n",
       "        [194, 169, 173]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:42:23.766216Z",
     "start_time": "2020-02-12T23:42:23.756245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite('./server/static/' + 'test_proccesed.jpg', processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:39:39.537912Z",
     "start_time": "2020-02-12T23:39:39.533966Z"
    }
   },
   "outputs": [],
   "source": [
    "? cv.imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. AWS로 구동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
