{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <오늘 할 것: 자연어 처리1>\n",
    "\n",
    "# 1. 들어가기\n",
    "- 1-1. 분포가설\n",
    "\n",
    "# 2. 언어 판별하기\n",
    "- 2-1. 한/일/영 분류하기\n",
    "- 2-2. 독/영/스 분류하기(문자셋이 동일한 경우)\n",
    "\n",
    "# 3. 빈도 분석하기\n",
    "- 3-1. 벡터화하기\n",
    "    - 3-1-1. TF 기반 `CountVectorizer`\n",
    "    - 3-1-2. TF-IDF 기반 `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 들어가기\n",
    "\n",
    "> 자연어 처리 == 컴퓨터 과학 + 인공지능 + 언어학\n",
    "\n",
    "- closed-domain의 경우 비교적 쉽다: 라마는 무슨 과? -> 낙타과\n",
    "    - open-domain은 곤란했다: 왜 나는 결혼을 못할까? -> ???\n",
    "    \n",
    "    \n",
    "- 돌파구: 단어의 **벡터화**를 통한 분산표현\n",
    "\n",
    "\n",
    "## 1-1. 분포가설\n",
    "\n",
    "> 비슷한 문맥을 가진 단어는 비슷한 의미를 갖는다.\n",
    "\n",
    "> \"You shall know a word by the company it keeps (J. R. Firth)\n",
    "    \n",
    "1. count-based method\n",
    "    - 빈도수 기반 분석\n",
    "    \n",
    "2. predictive method\n",
    "    - 학습을 통한 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 언어 판별하기\n",
    "\n",
    "필요한 모듈을 먼저 다운로드 받는다.\n",
    "- `conda install -c conda-forge jpype1`\n",
    "- `pip install konlpy`\n",
    "- `pip install gensim`\n",
    "- `pip install wordcloud`\n",
    "\n",
    "(이거 상엽이 알려줘야겠다..윈도우에서 konlpy 설치가 이렇게까지 쉽게 될 수 있다니........)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:38:26.816223Z",
     "start_time": "2020-02-07T02:38:26.806288Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from konlpy.tag import Twitter, Okt, Kkma, Twitter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from gensim import corpora, models\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "from wordcloud import ImageColorGenerator\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 한/일/영 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:21:33.545332Z",
     "start_time": "2020-02-07T01:21:33.541333Z"
    }
   },
   "outputs": [],
   "source": [
    "ko_str = \"이것은 한국어 문장입니다.\"\n",
    "ja_str = \"これは日本の文章です。\"\n",
    "en_str = \"This is English Sentence\"\n",
    "ch_str = \"這是中文句子。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:21:39.791988Z",
     "start_time": "2020-02-07T01:21:39.787890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이\n"
     ]
    }
   ],
   "source": [
    "print(ko_str[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ord` 함수는 ascii 코드(unicode) 값을 반환한다.\n",
    "- 문자는 모두 2 byte로 코드화되어 있다.\n",
    "- 0~66535까지 값을 갖는다.\n",
    "    ### - 이 점을 활용해서 특정 문장이 어떤 언어로 쓰였는지 판단할 수 있다.\n",
    "        - 0~66535번 코드 중 어떤 것이 활용되었는지; 빈도 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:22:12.233118Z",
     "start_time": "2020-02-07T01:22:12.220910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51060\n",
      "12371\n",
      "84\n",
      "36889\n"
     ]
    }
   ],
   "source": [
    "print(ord(ko_str[0]))\n",
    "print(ord(ja_str[0]))\n",
    "print(ord(en_str[0]))\n",
    "print(ord(ch_str[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영문자가 비교적 앞 번호다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:37:35.350862Z",
     "start_time": "2020-02-07T01:37:35.344878Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unicode 코드 포인트로 출현 빈도 판정하기 --- (*1)\n",
    "def count_codePoint(str):\n",
    "    # Unicode 코드 포인트를 저장할 배열 준비하기 --- (*2)\n",
    "    counter = np.zeros(65535)\n",
    "    for i in range(len(str)):\n",
    "        # 각 문자를 Unicode 코드 포인트로 변환하기 --- (*3)\n",
    "        code_point = ord(str[i])\n",
    "        if code_point > 65535 :\n",
    "            continue\n",
    "        # 출현 횟수 세기 --- (*4)\n",
    "        counter[code_point] += 1\n",
    "\n",
    "    # 각 요소를 문자 수로 나눠 정규화하기 --- (*5)\n",
    "    counter = counter/len(str)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:29:50.626400Z",
     "start_time": "2020-02-07T02:29:50.621412Z"
    }
   },
   "outputs": [],
   "source": [
    "#학습데이터 준비하기\n",
    "x_train = [count_codePoint(ko_str), count_codePoint(ja_str), count_codePoint(en_str)]\n",
    "y_train = ['ko', 'ja', 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:39:27.187136Z",
     "start_time": "2020-02-07T01:39:27.181157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(array([   32,    46, 44163, 44397, 45768, 45796, 47928, 50612, 51008,\n",
      "       51060, 51077, 51109, 54620], dtype=int64),)\n",
      "[0.14285714 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
      " 0.07142857]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])    #한국어 문장 출력값\n",
    "print(np.where(x_train[0] > 0))    #0이 아닌 데이터의 인덱스\n",
    "\n",
    "idx = np.where(x_train[0] > 0)\n",
    "data = x_train[0]\n",
    "print(data[idx])   #0이 아닌 데이터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T01:46:50.521095Z",
     "start_time": "2020-02-07T01:46:50.310225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x17d4960b448>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#숫자로 먼저 해보기\n",
    "\n",
    "#X = np.array([[-1, -1], [3, 2]])\n",
    "#Y = np.array([1,  2])\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "Y = np.array([1, 1, 1, 2, 2, 2])\n",
    "#Y = np.array(['r', 'r', 'r', 'b', 'b', 'b'])\n",
    "#y는 클래스를 구분하기 위한 것; 계산식에 포함되지 않는다; 클래스 구분만 가능하다면 아무렇게나 바꿔도 됨\n",
    "\n",
    "\n",
    "color = [ 'red' if y == 1 else 'blue' for y in Y]\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], color=color)\n",
    "\n",
    "t = np.array([[-0.8, -1]])\n",
    "\n",
    "plt.scatter(t[:,0], t[:,1], color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:06:43.980659Z",
     "start_time": "2020-02-07T02:06:43.973679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()    #Gaussian naive bayesian: 특정 값에 대한 확률값 계산\n",
    "clf.fit(X, Y)\n",
    "print(clf.predict([[-0.8, -1], [-2.5, 1.0], [0, 0], [1, 1]]))    #두 분포 중 어디에 속할 확률이 높은지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 별로 없어서 신경망을 쓸 수 없다.\n",
    "\n",
    "그래서 GaussianNB 쓴다. 딱히 성능이 좋아서는 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:29:52.457647Z",
     "start_time": "2020-02-07T02:29:52.445655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#이제 자연어로 해보기\n",
    "\n",
    "#학습시키기\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:13:54.617499Z",
     "start_time": "2020-02-07T02:13:54.605540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko']\n"
     ]
    }
   ],
   "source": [
    "#테스트 해보기\n",
    "y_pred = clf.predict([count_codePoint(\"안녕, 어디야?\")])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:15:03.739992Z",
     "start_time": "2020-02-07T02:15:03.733987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n"
     ]
    }
   ],
   "source": [
    "#테스트 해보기2\n",
    "y_pred = clf.predict([count_codePoint(\"hello, where are you?\")])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:15:50.355335Z",
     "start_time": "2020-02-07T02:15:50.349374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ja']\n"
     ]
    }
   ],
   "source": [
    "#테스트 해보기3\n",
    "y_pred = clf.predict([count_codePoint(\"こんにちは、どこだ？\")])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:16:38.644288Z",
     "start_time": "2020-02-07T02:16:38.637339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko']\n"
     ]
    }
   ],
   "source": [
    "#????\n",
    "y_pred = clf.predict([count_codePoint(\" \")])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습데이터의 한국어 문장에 띄어쓰기가 많이 들어가 있어서 값이 이렇게 나온다.\n",
    "\n",
    "(학습데이터가 편향되어 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:18:10.171753Z",
     "start_time": "2020-02-07T02:18:10.158380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en']\n"
     ]
    }
   ],
   "source": [
    "#????2\n",
    "y_pred = clf.predict([count_codePoint(\"안녕 こんにちは hello\")])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "흠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:29:56.762864Z",
     "start_time": "2020-02-07T02:29:56.748931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko' 'ja' 'en']\n",
      "['ko', 'ja', 'en']\n",
      "정답률 =  1.0\n"
     ]
    }
   ],
   "source": [
    "#분류 결과 평가하기\n",
    "\n",
    "#평가 전용 데이터 준비하기\n",
    "ko_test_str = \"안녕, 어디야?\"\n",
    "ja_test_str = \"こんにちは、どこだ？\"\n",
    "en_test_str = \"hello, where are you?\"\n",
    "x_test = [count_codePoint(ko_test_str), count_codePoint(ja_test_str), count_codePoint(en_test_str)]\n",
    "y_test = ['ko', 'ja', 'en']\n",
    "\n",
    "#평가하기\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print(\"정답률 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T02:29:58.420069Z",
     "start_time": "2020-02-07T02:29:58.406107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ko' 'ja' 'en']\n",
      "['ko', 'ja', 'en']\n",
      "정답률 =  1.0\n"
     ]
    }
   ],
   "source": [
    "#분류 결과 평가하기2: 데이터를 줄여본다.\n",
    "\n",
    "#평가 전용 데이터 준비하기\n",
    "ko_test_str = \"안녕\"\n",
    "ja_test_str = \"こんにちは\"\n",
    "en_test_str = \"hello\"\n",
    "x_test = [count_codePoint(ko_test_str), count_codePoint(ja_test_str), count_codePoint(en_test_str)]\n",
    "y_test = ['ko', 'ja', 'en']\n",
    "\n",
    "#평가하기\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print(\"정답률 = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 성능을 논하기에는 데이터가 너무 적기는 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 독/영/스 분류하기(문자셋이 동일한 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:07:50.270614Z",
     "start_time": "2020-02-07T04:07:50.119051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./language/train\\de_cat.txt\n",
      "./language/train\\de_dog.txt\n",
      "./language/train\\de_elephant.txt\n",
      "./language/train\\en_cat.txt\n",
      "./language/train\\en_dog.txt\n",
      "./language/train\\en_elephant.txt\n",
      "./language/train\\es_cat.txt\n",
      "./language/train\\es_dog.txt\n",
      "./language/train\\es_elephant.txt\n"
     ]
    }
   ],
   "source": [
    "#학습데이터 준비하기\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for file in glob.glob('./language/train/*.txt'):\n",
    "    print(file)\n",
    "    y_train.append(file[17:19])\n",
    "    with open(file, 'r', encoding = 'utf-8') as f:\n",
    "        x_train.append(count_codePoint(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:07:03.680789Z",
     "start_time": "2020-02-07T04:07:03.651362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습하기\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:07:07.117122Z",
     "start_time": "2020-02-07T04:07:07.111139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de']\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict([count_codePoint('hello, my name is ')])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:20:51.829763Z",
     "start_time": "2020-02-07T04:20:51.724029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de' 'en' 'es']\n",
      "정답률 =  1.0\n"
     ]
    }
   ],
   "source": [
    "#테스트하기\n",
    "x_test = []\n",
    "y_test = []\n",
    "for file in glob.glob('./language/test/*.txt'):\n",
    "    # 언어 정보를 추출하고 레이블로 지정하기\n",
    "    y_test.append(file[16:18])\n",
    "    \n",
    "    # 파일 내부의 문자열을 모두 추출한 뒤 빈도 배열로 변환한 뒤 입력 데이터로 사용하기\n",
    "    file_str = ''\n",
    "    for line in open(file, 'r', encoding='UTF8'):\n",
    "        file_str = file_str + line\n",
    "    #print(file_str)\n",
    "    x_test.append(count_codePoint(file_str)) \n",
    "\n",
    "# 평가하기\n",
    "y_pred = clf.predict(x_test)\n",
    "print(y_pred)\n",
    "print(\"정답률 = \" , accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 빈도 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:13:38.739403Z",
     "start_time": "2020-02-07T04:13:38.735423Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:21:49.603639Z",
     "start_time": "2020-02-07T04:21:49.599598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you know I want your love I like you what should I do\n",
      "['you', 'know', 'I', 'want', 'your', 'love', 'I', 'like', 'you', 'what', 'should', 'I', 'do']\n",
      "{'you': 2, 'know': 1, 'I': 3, 'want': 1, 'your': 1, 'love': 1, 'like': 1, 'what': 1, 'should': 1, 'do': 1}\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "str = \" \".join(corpus)\n",
    "print(str)\n",
    "\n",
    "words = str.split(' ')\n",
    "print(words)\n",
    "\n",
    "freq = {}\n",
    "for w in words:\n",
    "    freq[w] = freq.get(w, 0) + 1\n",
    "\n",
    "print(freq)\n",
    "print(freq['I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:24:08.843685Z",
     "start_time": "2020-02-07T04:24:08.839741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. 벡터화하기\n",
    "\n",
    "### 3-1-1. TF 기반 `CountVectorizer`\n",
    "\n",
    "> corpus를 사용된 전체 단어 목록인 vocabulary를 기반으로 one-hot encoding 하는 것\n",
    "\n",
    "> 0은 특정 단어가 없음, 1은 특정 단어가 있음을 의미한다.\n",
    "- 단순 존재 여부만을 계산하기 때문에 단어의 순서는 반영되지 않는다.\n",
    "\n",
    "1. `CountVectorizer()` 생성자 함수로 벡터라이저 객체를 생성하기\n",
    "\n",
    "\n",
    "2. `벡터라이저.fit_transform(코퍼스)`로 벡터화\n",
    "    - 코퍼스는 문장들의 리스트\n",
    "\n",
    "\n",
    "3. `벡터화결과.toarray()`로 dense matrix 형태로 출력\n",
    "\n",
    "\n",
    "4. 추가적으로 할 수 있는 것들\n",
    "    - `벡터라이저.vocabulary_`로 단어별 인덱스 확인(딕셔너리)\n",
    "        - **빈도수 아님**\n",
    "    - `벡터라이저.get_feature_names()`로 vocabulary 확인(리스트)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:26:36.115552Z",
     "start_time": "2020-02-07T04:26:36.111564Z"
    }
   },
   "outputs": [],
   "source": [
    "vector = CountVectorizer()   \n",
    "\n",
    "tf = vector.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:27:54.316423Z",
     "start_time": "2020-02-07T04:27:54.304531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 0)\t1\n",
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(tf)    #sparse matrix\n",
    "print(tf.toarray())    #dense matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer는 글자수 1개짜리를 모두 불용어 처리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:36:11.726315Z",
     "start_time": "2020-02-07T04:36:11.723388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 9)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape)   #문장, 단어 수(한글자짜리 제외)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:37:12.115350Z",
     "start_time": "2020-02-07T04:37:12.111399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T04:40:50.696832Z",
     "start_time": "2020-02-07T04:40:50.691830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', 'know', 'like', 'love', 'should', 'want', 'what', 'you', 'your']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1-2. TF-IDF 기반 `TfidfVectorizer`\n",
    "\n",
    "> Term Frequency - Inverse Document Frequency\n",
    "\n",
    "<img src=\"tfidf.jpg\">\n",
    "\n",
    "(정규화를 위해 N으로 나눠주고, 문서 수가 너무 커질 수 있기 때문에 log를 취해서 적절히 줄여주는 것)\n",
    "\n",
    "- TF : 현재 문서에서 단어 A가 나타난 횟수\n",
    "- DF : 단어가 나타난 문서의 수\n",
    "- 특정 단어의 상대적인 빈도를 나타내주는 값\n",
    "- 값이 클 수록 내 문서에만 많이 언급되는 단어(=다른 문서에서는 잘 언급 안됨)\n",
    "- 값이 작을수록 다른 문서에 잘 언급하는 단어를 의미(=현재 문서와 관련 없음)\n",
    "\n",
    "### => TF(단순빈도)에 비해 문서의 고유성을 나타내기에 더 적절하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:47.591416Z",
     "start_time": "2020-02-07T05:56:47.584476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t0.6437444595062429\n",
      "  (0, 7)\t0.7652405313723362\n",
      "  (1, 17)\t0.6437444595062429\n",
      "  (1, 7)\t0.7652405313723362\n",
      "  (2, 12)\t0.28487998702172107\n",
      "  (2, 6)\t0.28487998702172107\n",
      "  (2, 4)\t0.28487998702172107\n",
      "  (2, 1)\t0.28487998702172107\n",
      "  (2, 9)\t0.35310140100264525\n",
      "  (2, 14)\t0.28487998702172107\n",
      "  (2, 8)\t0.35310140100264525\n",
      "  (2, 13)\t0.35310140100264525\n",
      "  (2, 5)\t0.35310140100264525\n",
      "  (2, 17)\t0.19893117008503197\n",
      "  (2, 7)\t0.23647612349029334\n",
      "  (3, 11)\t0.3542556015420614\n",
      "  (3, 16)\t0.3542556015420614\n",
      "  (3, 3)\t0.3542556015420614\n",
      "  (3, 10)\t0.3542556015420614\n",
      "  (3, 0)\t0.3542556015420614\n",
      "  (3, 2)\t0.3542556015420614\n",
      "  (3, 15)\t0.3542556015420614\n",
      "  (3, 14)\t0.28581118874948447\n",
      "  (3, 17)\t0.1995814265359179\n",
      "  (4, 12)\t0.5\n",
      "  (4, 6)\t0.5\n",
      "  (4, 4)\t0.5\n",
      "  (4, 1)\t0.5\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(5, 18)\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.76524053 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.64374446]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.76524053 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.64374446]\n",
      " [0.         0.28487999 0.         0.         0.28487999 0.3531014\n",
      "  0.28487999 0.23647612 0.3531014  0.3531014  0.         0.\n",
      "  0.28487999 0.3531014  0.28487999 0.         0.         0.19893117]\n",
      " [0.3542556  0.         0.3542556  0.3542556  0.         0.\n",
      "  0.         0.         0.         0.         0.3542556  0.3542556\n",
      "  0.         0.         0.28581119 0.3542556  0.3542556  0.19958143]\n",
      " [0.         0.5        0.         0.         0.5        0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "sent = [\"오늘 휴일\", \n",
    "        \"휴일 오늘\", \n",
    "        \"휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다.\", \n",
    "        \"폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니 다.\", \n",
    "        \" 내일 은 반가운 비 소식 이 있습니다.\"] \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sent) #문장 벡터화 진행\n",
    "print(tfidf_matrix)\n",
    "print(type(tfidf_matrix))\n",
    "print(tfidf_matrix.toarray().shape)\n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:48.197041Z",
     "start_time": "2020-02-07T05:56:48.192060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['갑작스런',\n",
       " '내일',\n",
       " '놀러왔다가',\n",
       " '망연자실',\n",
       " '반가운',\n",
       " '서쪽',\n",
       " '소식',\n",
       " '오늘',\n",
       " '으로',\n",
       " '이어졌는데요',\n",
       " '인해',\n",
       " '있습니',\n",
       " '있습니다',\n",
       " '중심',\n",
       " '폭염',\n",
       " '피해서',\n",
       " '하고',\n",
       " '휴일']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:48.604413Z",
     "start_time": "2020-02-07T05:56:48.600418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'오늘': 7,\n",
       " '휴일': 17,\n",
       " '서쪽': 5,\n",
       " '중심': 13,\n",
       " '으로': 8,\n",
       " '폭염': 14,\n",
       " '이어졌는데요': 9,\n",
       " '내일': 1,\n",
       " '반가운': 4,\n",
       " '소식': 6,\n",
       " '있습니다': 12,\n",
       " '피해서': 15,\n",
       " '놀러왔다가': 2,\n",
       " '갑작스런': 0,\n",
       " '인해': 10,\n",
       " '망연자실': 3,\n",
       " '하고': 16,\n",
       " '있습니': 11}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:49.070555Z",
     "start_time": "2020-02-07T05:56:49.064573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.76524053 0.        ]\n",
      " [0.76524053 0.        ]\n",
      " [0.23647612 0.28487999]\n",
      " [0.         0.28581119]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.asarray(tfidf_matrix.toarray())\n",
    "srch = ['오늘', '폭염']\n",
    "srch_dtm = mat[:, [tfidf_vectorizer.vocabulary_.get(i) for i in srch]]   \n",
    "#문서별로 '오늘'과 '폭염'의 tfidf 값을 가져옴\n",
    "\n",
    "print(srch_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:49.915922Z",
     "start_time": "2020-02-07T05:56:49.912908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76524053 0.76524053 0.52135611 0.28581119 0.        ]\n"
     ]
    }
   ],
   "source": [
    "score = srch_dtm.sum(axis = 1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T05:56:50.404388Z",
     "start_time": "2020-02-07T05:56:50.399401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 휴일 / score : 0.7652405313723362\n",
      "휴일 오늘 / score : 0.7652405313723362\n",
      "휴일 인 오늘 도 서쪽 을 중심 으로 폭염 이 이어졌는데요, 내일 은 반가운 비 소식 이 있습니다. / score : 0.5213561105120144\n",
      "폭염 을 피해서 휴일 에 놀러왔다가 갑작스런 비 로 인해 망연자실 하고 있습니 다. / score : 0.28581118874948447\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(score)):\n",
    "    if score[i] > 0:\n",
    "        print('{} / score : {}'.format(sent[i], score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딱히 안 정확하다. '오늘', '폭염'을 기준으로 했을 때 생각하기에는 세번째 문장이 가장 높은 점수가 나와야하지만, 그렇지 않다.\n",
    "\n",
    "### 문장 길이의 영향을 받기 때문.\n",
    "\n",
    "'오늘 휴일'과 '휴일 오늘'에 무의미한 단어들을 추가해서 세번째 문장만큼의 길이로 늘리면 생각대로 세번째 문장이 '오늘', '폭염'과 가장 유사도가 높게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T06:26:26.666082Z",
     "start_time": "2020-02-07T06:26:26.661149Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ['This is the first document.',\n",
    "              'This is the second document.',\n",
    "              'And the third one.',\n",
    "              'Is this the first document?']\n",
    "vect = TfidfVectorizer()\n",
    "X = vect.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T06:26:27.429001Z",
     "start_time": "2020-02-07T06:26:27.418070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='perceptron',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [1,2,3,4]\n",
    "model =  SGDClassifier(loss='perceptron')  \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-07T06:26:28.910159Z",
     "start_time": "2020-02-07T06:26:28.905217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "X_pred = vect.transform(['My new document third'])\n",
    "y_pred = model.predict(X_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
